<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta
			name="viewport"
			content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
		/>

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css" />
		<link rel="stylesheet" href="dist/reveal.css" />
		<link rel="stylesheet" href="dist/theme/black.css" />
		<link rel="stylesheet" href="custom.css" />

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" />
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h3>Introduction to Machine Learning</h3>
				</section>

				<section>
					<h3>Tasks</h3>
					<ul>
						<li>Tabular Data</li>
						<li>Computer Vision</li>
						<li>Natural Language Processing (NLP)</li>
						<li>Reinforcement Learning</li>
						<li>Anomaly Detection</li>
					</ul>
				</section>

				<section>
					<h3>Tabular Data</h3>
					<ul>
						<li>Regression Tasks</li>
						<li>Classification Tasks</li>
						<li>Time Series Forecasting</li>
					</ul>
				</section>
				<section>
					<h3>Regression Tasks</h3>
					<p>
						Predicting continuous outcomes, such as sales forecasting or real
						estate pricing.
					</p>
				</section>
				<section>
					<h3>Classification Tasks</h3>
					<p>
						Categorizing data into predefined groups, like customer churn
						prediction or disease diagnosis.
					</p>
				</section>
				<section>
					<h3>Time Series Forecasting</h3>
					<p>
						Predicting future values based on historical time series data, like
						stock market trends or demand forecasting.
					</p>
				</section>

				<section>
					<h3>Computer Vision</h3>
					<ul>
						<li>Image Classification</li>
						<li>Object Detection</li>
						<li>Image Segmentation</li>
						<li>Video Analysis</li>
					</ul>
				</section>
				<section>
					<h3>Image Classification</h3>
					<blockquote>
						<img
							src="https://assets-global.website-files.com/614c82ed388d53640613982e/6475ee7f074119ae0c60c4bb_image%20classification%20data%20labeling.webp"
						/>
						<a
							href="https://www.labelbox.com/blog/image-classification-data-labeling"
							>What is image classification? Basics you need to know</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Object Detection</h3>
					<blockquote>
						<img
							src="https://deeplobe.ai/wp-content/uploads/2023/06/Object-detection-Real-world-applications-and-benefits.png"
						/>
						<a
							href="https://deeplobe.ai/exploring-object-detection-applications-and-benefits/"
							>Exploring Object Detection Applications and Benefits</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Image Segmentation</h3>
					<blockquote>
						<img
							src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*B16t8Do6hvuq2Q_2YOM-UQ.png"
						/>
						<a
							href="https://medium.com/visionwizard/object-segmentation-4fc67077a678"
							>Object Segmentation</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Video Analysis</h3>
					<blockquote>
						<img
							src="https://e0.365dm.com/20/11/1600x900/skysports-metrica-analytics_5170842.png?20201113110003"
						/>
						<a
							href="https://www.skysports.com/football/news/11095/12133219/footballs-video-analysis-revolution-from-barcelona-to-the-masses"
							>Football's video analysis revolution: From the top clubs to the
							masses</a
						>
					</blockquote>
				</section>

				<section>
					<h3>Natural Language Processing (NLP)</h3>
					<ul>
						<li>Sentiment Analysis</li>
						<li>Text Classification</li>
						<li>Machine Translation</li>
						<li>Named Entity Recognition (NER)</li>
					</ul>
				</section>
				<section>
					<h3>Sentiment Analysis</h3>
					<blockquote>
						<img
							src="https://monkeylearn.com/static/348bb1d70089176ca2f61ea402094382/b4ad3/main.png"
						/>
						<a href="https://monkeylearn.com/sentiment-analysis/"
							>Sentiment Analysis: A Definitive Guide</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Text Classification</h3>
					<blockquote>
						<img
							src="https://developers.google.com/static/machine-learning/guides/text-classification/images/TextClassificationExample.png"
						/>
						<a
							href="https://developers.google.com/machine-learning/guides/text-classification"
							>Text Classification</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Machine Translation</h3>
					<blockquote>
						<p>üá∫üá∏: I'm a cat.</p>
						<p>‚Üì</p>
						<p>üá®üá≥: ÊàëÊòØ‰∏ÄÂè™Áå´„ÄÇ</p>
						<p>üá©üá™: ich bin eine Katze</p>
						<p>üáØüáµ: ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã„ÄÇ</p>
					</blockquote>
				</section>
				<section>
					<h3>Named Entity Recognition (NER)</h3>
					<blockquote>
						<img
							src="https://cdn-images-1.medium.com/max/2000/1*7DkqpU3E-E9yknyw9c7vCQ.png"
						/>
						<a
							href="https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2"
							>Named Entity Recognition and Classification with Scikit-Learn</a
						>
					</blockquote>
				</section>

				<section>
					<h3>Reinforcement Learning</h3>
					<ul>
						<li>Game AI</li>
						<li>Simulation Optimization</li>
					</ul>
				</section>
				<section>
					<h3>Game AI</h3>
					<blockquote>
						<img
							src="https://miro.medium.com/max/924/1*-yhJ9Ma_fhxIBlacV1dP6A.gif" width="700rem"
						/>
						<a
							href="https://ppiconsulting.dev/blog/blog55/"
							>Getting Started With Reinforcement Learning</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Simulation Optimization</h3>
					<blockquote>
						<img
							src="https://blog.paperspace.com/content/images/2020/11/openaigym.jpg"
						/>
						<a
							href="https://blog.paperspace.com/getting-started-with-openai-gym/"
							>Getting Started With OpenAI Gym: The Basic Building Blocks</a
						>
					</blockquote>
				</section>

				<section>
					<h3>Anomaly Detection</h3>
					<ul>
						<li>Fraud Detection</li>
						<li>Network Intrusion Detection</li>
					</ul>
				</section>
				<section>
					<h3>Fraud Detection</h3>
					<p>Identifying fraudulent activities in financial transactions.</p>
				</section>
				<section>
					<h3>Network Intrusion Detection</h3>
					<p>Detecting malicious activities in network traffic.</p>
				</section>

				<section>
					<h3>Machine Learning Algorithms</h3>
					<ul>
						<li>Linear Regression</li>
						<li>Logistic Regression</li>
						<li>Decision Tree</li>
						<li>SVM (Support Vector Machine)</li>
						<li>Naive Bayes Algorithm</li>
						<li>KNN (K-Nearest Neighbors) Algorithm</li>
						<li>K-Means</li>
						<li>Random Forest Algorithm</li>
						<li>Gradient Boosting</li>
					</ul>
				</section>
				<section>
					<h3>Linear Regression</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/ezgif.com-video-to-gif-1.gif" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
				</section>
				<section>
					<h3>Logistic Regression</h3>
					<blockquote>
						<img src="https://editor.analyticsvidhya.com/uploads/450101_2KAInY20QPhkLCJ8jWVLJw.gif" />
						<a
							href="https://www.analyticsvidhya.com/blog/2021/10/building-an-end-to-end-logistic-regression-model/"
							>Building an End-to-End Logistic Regression Model</a>
					</blockquote>
				</section>
				<section>
					<h3>Decision Tree</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/tree.gif" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
				</section>
				<section>
					<h3>SVM (Support Vector Machine)</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/svm.gif" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
				</section>
				<section>
					<h3>Naive Bayes Algorithm</h3>
					\[\begin{aligned}
						P(A|B) &= \frac{P(B|A)P(A)}{P(B)}
					\end{aligned}\]
				</section>
				<section>
					<h3>KNN (K-Nearest Neighbors) Algorithm</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/knn.gif" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
				</section>
				<section>
					<h3>K-Means</h3>
					<blockquote>
						<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/K-means_convergence.gif/617px-K-means_convergence.gif" />
						<a
							href="https://en.m.wikipedia.org/wiki/File:K-means_convergence.gif"
							>File:K-means convergence.gif</a>
					</blockquote>
				</section>
				<section>
					<h3>Random Forest Algorithm</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/randomforest.gif" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
				</section>
				<section>
					<h3>Gradient Boosting</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/xgboost.gif" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
				</section>

				<!-- Exploratory Data Analysis (EDA) -->
				<section>
					<h3>Exploratory Data Analysis (EDA)</h3>
				</section>
				<section>
					<h3>Get domain knowledge.</h3>
					<p>If you know that many people take taxi to the airport, you can add the distance to the airport as a feature.</p>
				</section>
				<section>
					<h3>Descriptive Statistics</h3>
					<pre><code>
							df.describe()
							#        count       mean       std  min   25%   50%   75%   max
							# var1  1000.0  12.542000  6.735307  0.0  8.00  12.0  18.0  24.0
							# var2  1000.0   0.255000  0.435941  0.0  0.00   0.0   1.0   1.0
					</code></pre>
				</section>
				<section>
					<h3>Find missing data.</h3>
					<pre><code>
						df.isnull().sum()
						# var1          12
						# var2		      3
						# dtype: int64
					</code></pre>
				</section>
				<section>
					<h3>Correlation Matrix</h3>
					<pre><code>
							df.corr()
							#             var1      var2
							# var1   1.000000 -0.121675
							# var2  -0.121675  1.000000
					</code></pre>
				</section>

				<section>
					<h3>Value Counts for Categorical Data</h3>
					<pre><code>
							df['Column3'].value_counts()
							# True     500
							# False    490
							# NaN       10
					</code></pre>
			</section>
			<section>
					<h3>Unique Values in a Column</h3>
					<pre><code>
							df['Column2'].unique()
							# array([5, 6, 7, ..., 53, 54, 55])
					</code></pre>
			</section>
			
			<section>
					<h3>Histograms</h3>
					<pre><code>
						df['Column2'].hist()
					</code></pre>
					<img src="https://masaishi-blog.s3.us-west-1.amazonaws.com/hist.png" alt="Histogram of Column1">
			</section>
			
			<section>
					<h3>Box Plots</h3>
					<pre><code>
						df.boxplot(column=["Column1", "Column2"])
					</code></pre>
					<img src="https://masaishi-blog.s3.us-west-1.amazonaws.com/boxplot.png" alt="Boxplot of Column1">
			</section>
			
			<section>
					<h3>Scatter Plot</h3>
					<pre><code>
						df.plot.scatter(x='Column1', y='Column2')
					</code></pre>
					<img src="https://masaishi-blog.s3.us-west-1.amazonaws.com/scatter.png" alt="Scatter Plot of Column1 vs Column2">
			</section>
			
			<section>
					<h3>Heatmap for Correlation</h3>
					<pre><code>
						sns.heatmap(df.corr(), annot=True)
					</code></pre>
					<img src="https://masaishi-blog.s3.us-west-1.amazonaws.com/heatmap_coor.png" alt="Correlation Heatmap">
			</section>



				<!-- Data Preprocessing -->
				<section>
					<h3>Data Preprocessing</h3>
				</section>
				<section>
					<h3>Handling Missing Values</h3>
					<pre><code>
						# Fill missing values
						df.fillna(value)
		
						# Drop rows/columns with missing values
						df.dropna(axis=0, how='any')
					</code></pre>
				</section>
				
				<section>
					<h3>Data Type Conversion</h3>
					<pre><code>
						df['column'].astype('dtype')
					</code></pre>
				</section>
				
				<section>
					<h3>Outlier Removal</h3>
					<pre><code>
							df[df['column'] < upper_limit]
					</code></pre>
				</section>
				
				<section>
					<h3>Normalization and Scaling</h3>
					<pre><code>
from sklearn.preprocessing import MinMaxScaler, StandardScaler
scaler = MinMaxScaler()  # or StandardScaler()
df_scaled = scaler.fit_transform(df)
					</code></pre>
				</section>
				
				<section>
					<h3>Encoding Categorical Data</h3>
					<pre><code>
# Using get_dummies
pd.get_dummies(df, columns=['categorical_column'])

# Using category codes
df['categorical_column'] = df['categorical_column'].astype('category').cat.codes
					</code></pre>
				</section>
				
				<section>
					<h3>Feature Engineering</h3>
					<pre><code>
						df['new_feature'] = df['column1'] / df['column2']
					</code></pre>
				</section>
				
				<section>
					<h3>Handling Date and Time</h3>
					<pre><code>
						df['year'] = df['datetime_column'].dt.year
					</code></pre>
				</section>
				
				<section>
					<h3>Dimensionality Reduction</h3>
					<pre><code>
						from sklearn.decomposition import PCA
						pca = PCA(n_components=k)
						df_reduced = pca.fit_transform(df)
					</code></pre>
				</section>

				<!-- Validation -->
				<section>
					<h3>Validation</h3>
				</section>
				<section>
					<h3>Hold-Out Validation</h3>
					<pre><code>
						from sklearn.model_selection import train_test_split
						X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2)
					</code></pre>
				</section>
				
				<section>
					<h3>K-Fold Cross-Validation</h3>
					<pre><code>
						from sklearn.model_selection import cross_val_score, KFold
						kf = KFold(n_splits=5)
						scores = cross_val_score(model, X, y, cv=kf)
					</code></pre>
				</section>
				
				<section>
					<h3>Stratified K-Fold Cross-Validation</h3>
					<pre><code>
						from sklearn.model_selection import StratifiedKFold
						skf = StratifiedKFold(n_splits=5)
						scores = cross_val_score(model, X, y, cv=skf)
					</code></pre>
				</section>

				<!-- Metrics Optimization -->
				<section>
					<h3>Metrics Optimization</h3>
				</section>
				<section>
					<h3>Accuracy</h3>
					<pre><code>
						from sklearn.metrics import accuracy_score
						accuracy = accuracy_score(y_true, y_pred)
					</code></pre>
				</section>
				
				<section>
					<h3>Precision, Recall, and F1 Score</h3>
					<pre><code>
						from sklearn.metrics import precision_score, recall_score, f1_score
						precision = precision_score(y_true, y_pred)
						recall = recall_score(y_true, y_pred)
						f1 = f1_score(y_true, y_pred)
					</code></pre>

					<!-- ÂÅΩÈôΩÊÄß(False Positive)„ÇíÊ∏õ„Çâ„Åó„Åü„Åã„Å£„Åü„ÇâÈÅ©ÂêàÁéáÔºàprecision) -->
					<!-- ÂÅΩÈô∞ÊÄß(False Negative)„ÇíÊ∏õ„Çâ„Åó„Åü„Åã„Å£„Åü„ÇâÂÜçÁèæÁéáÔºàrecallÔºâ -->
					<!-- F1„ÅØ (2*precision*recall) / (precision + recall) -->
					<!-- https://note.nkmk.me/python-sklearn-confusion-matrix-score/ -->
				</section>
				
				<section>
						<h3>ROC-AUC Score</h3>
						<pre><code>
								from sklearn.metrics import roc_auc_score
								roc_auc = roc_auc_score(y_true, y_scores)
						</code></pre>
				</section>
				
				<section>
						<h3>Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)</h3>
						<pre><code>
								from sklearn.metrics import mean_squared_error
								mse = mean_squared_error(y_true, y_pred)
								rmse = mean_squared_error(y_true, y_pred, squared=False)
						</code></pre>
				</section>
				
				<section>
						<h3>Mean Absolute Error (MAE)</h3>
						<pre><code>
								from sklearn.metrics import mean_absolute_error
								mae = mean_absolute_error(y_true, y_pred)
						</code></pre>
				</section>
				
				<section>
						<h3>Log Loss</h3>
						<pre><code>
								from sklearn.metrics import log_loss
								logloss = log_loss(y_true, y_pred_probs)
						</code></pre>
				</section>

				<!-- Ensembling -->
				<section>
					<h3>Ensembling</h3>
				</section>
				<section>
					<h3>Averaging</h3>
					<pre><code>
							predictions = (model1.predict(X_test) + model2.predict(X_test) + model3.predict(X_test)) / 3
					</code></pre>
				</section>
				
				<section>
					<h3>Weighted Averaging</h3>
					<pre><code>
						weights = [0.3, 0.4, 0.3]
						predictions = weights[0]*model1.predict(X_test) + weights[1]*model2.predict(X_test) + weights[2]*model3.predict(X_test)
					</code></pre>
				</section>
				
				<section>
					<h3>Bagging</h3>
					<pre><code>
						from sklearn.ensemble import BaggingClassifier
						bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)
						bagging_model.fit(X_train, y_train)
						predictions = bagging_model.predict(X_test)
					</code></pre>
					<!-- Âêå„Åò„É¢„Éá„É´„Çí„ÄÅÈÅï„ÅÜ„Çµ„É≥„Éó„É´Êï∞„Åß‰∏¶Âàó„Å´Â≠¶Áøí„Åï„Åõ„Åü„ÅÇ„Å®„ÄÅ„Åù„ÅÆÁµêÊûú„ÅÆÂπ≥Âùá„ÇíÂèñ„Çã„ÄÇ -->
				</section>
				
				<section>
					<h3>Boosting</h3>
					<pre><code>
						from sklearn.ensemble import GradientBoostingClassifier
						boosting_model = GradientBoostingClassifier(n_estimators=100)
						boosting_model.fit(X_train, y_train)
						predictions = boosting_model.predict(X_test)
					</code></pre>
					<!-- Áõ¥Âàó„ÅÆ„Çà„ÅÜ„Å´Â≠¶Áøí„Åó„Åü„É¢„Éá„É´„ÇíÊõ¥„Å´Â≠¶Áøí„Åó„Å¶„ÄÅ10 steps„ÅÆ„É¢„Éá„É´„ÅÆÁµêÊûú „Å® 20 steps „ÅÆ„É¢„Éá„É´„ÅÆÁµêÊûú„ÅÆÂπ≥Âùá„ÇíÂèñ„Çã„ÄÇ -->
				</section>
				
				<section>
					<h3>Stacking</h3>
					<pre><code>
						from sklearn.ensemble import StackingClassifier
						from sklearn.linear_model import LogisticRegression
						estimators = [
								('rf', RandomForestClassifier(n_estimators=10, random_state=42)),
								('svr', make_pipeline(StandardScaler(), LinearSVC(random_state=42)))
						]
						stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())
						stacking_model.fit(X_train, y_train)
						predictions = stacking_model.predict(X_test)
					</code></pre>
					<!-- ÈÅï„ÅÜ„É¢„Éá„É´„ÅÆ‰∫àÊ∏¨ÁµêÊûú„ÇíÂÖ•Âäõ„Å´„É¢„Éá„É´„ÇíÂ≠¶Áøí„Åô„Çã -->
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX],
			});
		</script>
	</body>
</html>
