<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta
			name="viewport"
			content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
		/>

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css" />
		<link rel="stylesheet" href="dist/reveal.css" />
		<link rel="stylesheet" href="dist/theme/black.css" />
		<link rel="stylesheet" href="custom.css" />

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" />
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h3>Introduction to Machine Learning</h3>
				</section>

				<section>
					<h3>Table of Contents</h3>
					<ul>
						<li><a href="#/tasks">Tasks</a></li>
						<li><a href="#/machine-learning-algorithms">Machine Learning Algorithms</a></li>
						<li><a href="#/eda">Exploratory Data Analysis (EDA)</a></li>
						<li><a href="#/data-preprocessing">Data Preprocessing</a></li>
						<li><a href="#/validation">Validation</a></li>
						<li><a href="#/metrics-optimization">Metrics Optimization</a></li>
						<li><a href="#/ensembling">Ensembling</a></li>
					</ul>
				</section>

				<section id="tasks">
					<h3>Tasks</h3>
					<ul>
						<li><a href="#/tabular-data">Tabular Data</a></li>
						<li><a href="#/computer-vision">Computer Vision</a></li>
						<li><a href="#/natural-language-processing-nlp">Natural Language Processing (NLP)</a></li>
						<li><a href="#/reinforcement-learning">Reinforcement Learning</a></li>
						<li><a href="#/anomaly-detection">Anomaly Detection</a></li>
					</ul>
				</section>

				<section id="tabular-data">
					<h3>Tabular Data</h3>
					<ul>
						<li>Regression Tasks</li>
						<li>Classification Tasks</li>
						<li>Time Series Forecasting</li>
					</ul>
				</section>
				<section>
					<h3>Regression Tasks</h3>
					<p>
						Predicting continuous outcomes, such as sales forecasting or real
						estate pricing.
					</p>
				</section>
				<section>
					<h3>Classification Tasks</h3>
					<p>
						Categorizing data into predefined groups, like customer churn
						prediction or disease diagnosis.
					</p>
				</section>
				<section>
					<h3>Time Series Forecasting</h3>
					<p>
						Predicting future values based on historical time series data, like
						stock market trends or demand forecasting.
					</p>
				</section>

				<section id="computer-vision">
					<h3>Computer Vision</h3>
					<ul>
						<li>Image Classification</li>
						<li>Object Detection</li>
						<li>Image Segmentation</li>
						<li>Video Analysis</li>
					</ul>
				</section>
				<section>
					<h3>Image Classification</h3>
					<blockquote>
						<img
							src="https://assets-global.website-files.com/614c82ed388d53640613982e/6475ee7f074119ae0c60c4bb_image%20classification%20data%20labeling.webp"
						/>
						<a
							href="https://www.labelbox.com/blog/image-classification-data-labeling"
							>What is image classification? Basics you need to know</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Object Detection</h3>
					<blockquote>
						<img
							src="https://deeplobe.ai/wp-content/uploads/2023/06/Object-detection-Real-world-applications-and-benefits.png"
						/>
						<a
							href="https://deeplobe.ai/exploring-object-detection-applications-and-benefits/"
							>Exploring Object Detection Applications and Benefits</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Image Segmentation</h3>
					<blockquote>
						<img
							src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*B16t8Do6hvuq2Q_2YOM-UQ.png"
						/>
						<a
							href="https://medium.com/visionwizard/object-segmentation-4fc67077a678"
							>Object Segmentation</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Video Analysis</h3>
					<blockquote>
						<img
							src="https://e0.365dm.com/20/11/1600x900/skysports-metrica-analytics_5170842.png?20201113110003"
						/>
						<a
							href="https://www.skysports.com/football/news/11095/12133219/footballs-video-analysis-revolution-from-barcelona-to-the-masses"
							>Football's video analysis revolution: From the top clubs to the
							masses</a
						>
					</blockquote>
				</section>

				<section id="natural-language-processing-nlp">
					<h3>Natural Language Processing (NLP)</h3>
					<ul>
						<li>Sentiment Analysis</li>
						<li>Text Classification</li>
						<li>Machine Translation</li>
						<li>Named Entity Recognition (NER)</li>
					</ul>
				</section>
				<section>
					<h3>Sentiment Analysis</h3>
					<blockquote>
						<img
							src="https://monkeylearn.com/static/348bb1d70089176ca2f61ea402094382/b4ad3/main.png"
						/>
						<a href="https://monkeylearn.com/sentiment-analysis/"
							>Sentiment Analysis: A Definitive Guide</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Text Classification</h3>
					<blockquote>
						<img
							src="https://developers.google.com/static/machine-learning/guides/text-classification/images/TextClassificationExample.png"
						/>
						<a
							href="https://developers.google.com/machine-learning/guides/text-classification"
							>Text Classification</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Machine Translation</h3>
					<blockquote>
						<p>üá∫üá∏: I'm a cat.</p>
						<p>‚Üì</p>
						<p>üá®üá≥: ÊàëÊòØ‰∏ÄÂè™Áå´„ÄÇ</p>
						<p>üá©üá™: ich bin eine Katze</p>
						<p>üáØüáµ: ÂêæËº©„ÅØÁå´„Åß„ÅÇ„Çã„ÄÇ</p>
					</blockquote>
				</section>
				<section>
					<h3>Named Entity Recognition (NER)</h3>
					<blockquote>
						<img
							src="https://cdn-images-1.medium.com/max/2000/1*7DkqpU3E-E9yknyw9c7vCQ.png"
						/>
						<a
							href="https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2"
							>Named Entity Recognition and Classification with Scikit-Learn</a
						>
					</blockquote>
					<!-- Âõ∫ÊúâË°®ÁèæÊäΩÂá∫ -->
				</section>

				<section id="reinforcement-learning">
					<h3>Reinforcement Learning</h3>
					<ul>
						<li>Game AI</li>
						<li>Simulation Optimization</li>
					</ul>
				</section>
				<section>
					<h3>Game AI</h3>
					<blockquote>
						<img
							src="https://miro.medium.com/max/924/1*-yhJ9Ma_fhxIBlacV1dP6A.gif" width="700rem"
						/>
						<a
							href="https://ppiconsulting.dev/blog/blog55/"
							>Getting Started With Reinforcement Learning</a
						>
					</blockquote>
				</section>
				<section>
					<h3>Simulation Optimization</h3>
					<blockquote>
						<img
							src="https://blog.paperspace.com/content/images/2020/11/openaigym.jpg"
						/>
						<a
							href="https://blog.paperspace.com/getting-started-with-openai-gym/"
							>Getting Started With OpenAI Gym: The Basic Building Blocks</a
						>
					</blockquote>
				</section>

				<section id="anomaly-detection">
					<h3>Anomaly Detection</h3>
					<ul>
						<li>Fraud Detection</li>
						<li>Network Intrusion Detection</li>
					</ul>
					<!-- Áï∞Â∏∏Ê§úÁü• -->
				</section>
				<section>
					<h3>Fraud Detection</h3>
					<p>Identifying fraudulent activities in financial transactions.</p>
					<!-- ‰∏çÊ≠£Ê§úÁü•(Ë©êÊ¨∫ÂØæÁ≠ñ„Å™„Å©) -->
				</section>
				<section>
					<h3>Network Intrusion Detection</h3>
					<p>Detecting malicious activities in network traffic.</p>
					<!-- ‰æµÂÖ•Ê§úÁü•„Ç∑„Çπ„ÉÜ„É† -->
				</section>

				<section id="machine-learning-algorithms">
					<h3>Machine Learning Algorithms</h3>
					<ul>
						<li>Liner Regression</li>
						<li>Logistic Regression</li>
						<li>Decision Tree</li>
						<li>SVM (Support Vector Machine)</li>
						<li>Naive Bayes Algorithm</li>
						<li>KNN (K-Nearest Neighbors) Algorithm</li>
						<li>K-Means</li>
						<li>Random Forest Algorithm</li>
						<li>Gradient Boosting</li>
					</ul>
				</section>
				<section>
					<h3>Linear Regression</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/ezgif.com-video-to-gif-1.gif" height="500rem" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
					<!-- ÂõûÂ∏∞ÂïèÈ°å„Å´Áî®„ÅÑ„Çâ„Çå„Çã -->
					<!-- Kaggle„Åß„ÅØRidge Regression„Åå‰Ωø„Çè„Çå„Çã„Åì„Å®„ÅåÂ§ö„ÅÑ„ÄÇ -->
					<!-- from sklearn.linear_model import Ridge -->
				</section>
				<section>
					<h3>Logistic Regression</h3>
					<blockquote>
						<img src="https://editor.analyticsvidhya.com/uploads/450101_2KAInY20QPhkLCJ8jWVLJw.gif" height="500rem" />
						<a
							href="https://www.analyticsvidhya.com/blog/2021/10/building-an-end-to-end-logistic-regression-model/"
							>Building an End-to-End Logistic Regression Model</a>
					</blockquote>
					<!-- ÂàÜÈ°ûÂïèÈ°å„Å´Áî®„ÅÑ„Çâ„Çå„Çã„ÄÇ -->
				</section>

				<section>
					<h3>Decision Tree</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/tree.gif" height="500rem" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
				</section>
				<section>
					<h3>SVM (Support Vector Machine)</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/svm.gif" height="500rem" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
					<!-- SVM„ÅØ„Éá„Éº„Çø„ÇíÂàÜÈ°û„Åô„Çã„Åü„ÇÅ„Å´„ÄÅ„Éá„Éº„Çø„Éù„Ç§„É≥„Éà„ÅÆÈñì„Å´ÊúÄ„ÇÇËâØ„ÅÑ„ÄåÂ¢ÉÁïåÁ∑ö„Äç„ÇíÂºï„Åç„Åæ„Åô„ÄÇ
						„Åó„Åã„Åó„ÄÅÂÆüÈöõ„ÅÆ„Éá„Éº„Çø„ÅØ„ÅÑ„Å§„ÇÇ„Åç„Çå„ÅÑ„Å´Áõ¥Á∑ö„ÅßÂàÜ„Åë„Çâ„Çå„Çã„Çè„Åë„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ
						„Ç§„É°„Éº„Ç∏„Åß„Åô„Åå„ÄÅx„ÇíÊ®™Ëª∏„ÄÅx^2„ÅÆÁ∏¶Ëª∏„Å´„Åô„Çã„Å®
						y
						‚Üë	-------------------
						|	-------------------
						|	-A-A---B-B--A-A---- 
						|	-------------------
						|	-------------------
						---------------------‚Üí x
						„ÅÆ„Çà„ÅÜ„Å™„Éá„Éº„Çø„Åå
						x^2
						‚Üë
						| --------------A---
						| ------------------
						| ------------------
						| ------------A-----
						| ------------------
						| ------------------
						| ------------------
						| ---------B--------
						|	-------B----------
						| ---A--------------
						|	-A----------------
						---------------------‚Üí x
						„ÅÆ„Çà„ÅÜ„Å´Á∑öÂΩ¢„ÅßÂàÜÈ°û„Åß„Åç„Çã„Çà„ÅÜ„Å´„Å™„Çã„ÄÇ
					-->
				</section>
				<section>
					<h3>Naive Bayes Algorithm</h3>
					\[\begin{aligned}
						P(A|B) &= \frac{P(B|A)P(A)}{P(B)}
					\end{aligned}\]
					<!-- B„ÅåËµ∑„Åì„Å£„Åü„Å®„Åç„Å´A„ÅåËµ∑„Åì„ÇãÁ¢∫Áéá -->
					<!-- P(A)„ÅØ„ÄåA„ÅåËµ∑„Åì„ÇãÁ¢∫Áéá„Äç„Åß„ÄÅ„Åì„Çå„ÅØÊúÄÂàù„Å´ÊåÅ„Å£„Å¶„ÅÑ„ÇãÊÉÖÂ†±„ÇÑ‰ø°Âøµ„Å´Âü∫„Å•„Åç„Åæ„Åô„ÄÇ -->
					<!--P(B‚à£A)„ÅØ„ÄåA„ÅåËµ∑„Åì„Å£„Åü„Å®„Åç„Å´B„ÅåËµ∑„Åì„ÇãÁ¢∫Áéá„Äç„Åß„ÄÅÊñ∞„Åó„ÅÑË®ºÊã†„ÇÑ„Éá„Éº„Çø„Åå„Å©„ÅÆ„Çà„ÅÜ„Å´A„Å´Èñ¢ÈÄ£„Åó„Å¶„ÅÑ„Çã„Åã„ÇíÁ§∫„Åó„Åæ„Åô„ÄÇ-->
					<!--P(B)„ÅØ„ÄåB„ÅåËµ∑„Åì„ÇãÁ¢∫Áéá„Äç„Åß„ÄÅÂÖ®‰Ωì„ÅÆÊñáËÑà„ÇÑÂèØËÉΩÊÄß„ÇíË°®„Åó„Åæ„Åô„ÄÇ-->
					<!--
						„Éô„Ç§„Ç∫Áµ±Ë®à„ÇíÁî®„ÅÑ„Åü„Çπ„Éë„É†„É°„Éº„É´ÂàÜÈ°û„ÅØ„ÄÅ„É°„Éº„É´„Å´Âê´„Åæ„Çå„ÇãÁâπÂÆö„ÅÆÂçòË™û„ÇÑ„Éï„É¨„Éº„Ç∫„ÅÆÂá∫ÁèæÈ†ªÂ∫¶„Å´Âü∫„Å•„ÅÑ„Å¶„ÄÅ
						„É°„Éº„É´„Åå„Çπ„Éë„É†„Åß„ÅÇ„ÇãÂèØËÉΩÊÄß„ÇíË®àÁÆó„Åó„Åæ„Åô„ÄÇÂêÑÂçòË™û„Åå„Çπ„Éë„É†„É°„Éº„É´„Å´„Å©„Çå„Å†„ÅëÁâπÊúâ„Åã„ÇíÂàÜÊûê„Åó„ÄÅ
						„Åì„Çå„Çâ„ÅÆÊÉÖÂ†±„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Çã„Åì„Å®„Åß„ÄÅ„É°„Éº„É´„ÅÆÂÖ®‰ΩìÁöÑ„Å™ÂÜÖÂÆπ„ÇíËÄÉÊÖÆ„Åó„Åü‰∏ä„Åß„ÄÅ„Çπ„Éë„É†„ÅãÂê¶„Åã„Çí„Çà„ÇäÊ≠£Á¢∫„Å´Âà§Êñ≠„Åß„Åç„Åæ„Åô„ÄÇ
						Êñ∞„Åó„ÅÑÁ®ÆÈ°û„ÅÆ„Çπ„Éë„É†„É°„Éº„É´„ÅåÁèæ„Çå„ÅüÂ†¥Âêà„Åß„ÇÇ„ÄÅÊó¢Â≠ò„ÅÆ„Éá„Éº„Çø„Åã„ÇâÂ≠¶Áøí„Åó„ÄÅÂàÜÈ°û„ÅÆÁ≤æÂ∫¶„ÇíÁ∂ôÁ∂öÁöÑ„Å´Âêë‰∏ä„Åï„Åõ„Çã„Åì„Å®„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ
						„Åì„ÅÆ„Çà„ÅÜ„Å™ÁâπÂæ¥„Åå„ÄÅ„Éô„Ç§„Ç∫Áµ±Ë®à„Å´„Çà„Çã„Çπ„Éë„É†„É°„Éº„É´ÂàÜÈ°û„ÅÆÁ≤æÂ∫¶„ÇíÈ´ò„ÇÅ„Å¶„ÅÑ„Åæ„Åô„ÄÇ
					-->
				</section>
				<section>
					<h3>KNN (K-Nearest Neighbors) Algorithm</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/knn.gif" height="500rem" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
					<!-- ÊïôÂ∏´„ÅÇ„ÇäÂ≠¶Áøí -->
				</section>
				<section>
					<h3>K-Means</h3>
					<blockquote>
						<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/K-means_convergence.gif/617px-K-means_convergence.gif" height="550rem" />
						<a
							href="https://en.m.wikipedia.org/wiki/File:K-means_convergence.gif"
							>File:K-means convergence.gif</a>
					</blockquote>
					<!-- ÊïôÂ∏´„Å™„ÅóÂ≠¶Áøí -->
				</section>
				<section>
					<h3>Random Forest Algorithm</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/randomforest.gif" height="500rem" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
				</section>
				<section>
					<h3>Gradient Boosting</h3>
					<blockquote>
						<img src="https://paulvanderlaken.files.wordpress.com/2020/01/xgboost.gif" height="500rem" />
						<a
							href="https://paulvanderlaken.com/2020/01/20/animated-machine-learning-classifiers/"
							>Animated Machine Learning Classifiers</a>
					</blockquote>
				</section>

				<!-- Exploratory Data Analysis (EDA) -->
				<section id="eda">
					<h3>Exploratory Data Analysis (EDA)</h3>
				</section>
				<section>
					<h3>Get domain knowledge.</h3>
					<p>If you know that many people take taxi to the airport, you can add the distance to the airport as a feature.</p>
				</section>
				<section>
					<h3>Descriptive Statistics</h3>
					<pre><code>
df.describe()
#        count       mean       std  min   25%   50%   75%   max
# var1  1000.0  12.542000  6.735307  0.0  8.00  12.0  18.0  24.0
# var2  1000.0   0.255000  0.435941  0.0  0.00   0.0   1.0   1.0
					</code></pre>
				</section>
				<section>
					<h3>Find missing data.</h3>
					<pre><code>
						df.isnull().sum()
						# var1          12
						# var2		      3
						# dtype: int64
					</code></pre>
				</section>
				<section>
					<h3>Correlation Matrix</h3>
					<pre><code>
							df.corr()
							#             var1      var2
							# var1   1.000000 -0.121675
							# var2  -0.121675  1.000000
					</code></pre>
				</section>

				<section>
					<h3>Value Counts for Categorical Data</h3>
					<pre><code>
							df['Column3'].value_counts()
							# True     500
							# False    490
							# NaN       10
					</code></pre>
			</section>
			<section>
					<h3>Unique Values in a Column</h3>
					<pre><code>
							df['Column2'].unique()
							# array([5, 6, 7, ..., 53, 54, 55])
					</code></pre>
			</section>
			
			<section>
					<h3>Histograms</h3>
					<pre><code>
						df['Column2'].hist()
					</code></pre>
					<img src="https://masaishi-blog.s3.us-west-1.amazonaws.com/hist.png" alt="Histogram of Column1">
			</section>
			
			<section>
					<h3>Box Plots</h3>
					<pre><code>
						df.boxplot(column=["Column1", "Column2"])
					</code></pre>
					<img src="https://masaishi-blog.s3.us-west-1.amazonaws.com/boxplot.png" alt="Boxplot of Column1">
			</section>
			
			<section>
					<h3>Scatter Plot</h3>
					<pre><code>
						df.plot.scatter(x='Column1', y='Column2')
					</code></pre>
					<img src="https://masaishi-blog.s3.us-west-1.amazonaws.com/scatter.png" alt="Scatter Plot of Column1 vs Column2">
			</section>
			
			<section>
					<h3>Heatmap for Correlation</h3>
					<pre><code>
						sns.heatmap(df.corr(), annot=True)
					</code></pre>
					<img src="https://masaishi-blog.s3.us-west-1.amazonaws.com/heatmap_coor.png" alt="Correlation Heatmap">
			</section>



				<!-- Data Preprocessing -->
				<section id="data-preprocessing">
					<h3>Data Preprocessing</h3>
				</section>
				<section>
					<h3>Handling Missing Values</h3>
					<pre><code>
						# Fill missing values
						df.fillna(value)
		
						# Drop rows/columns with missing values
						df.dropna(axis=0, how='any')
					</code></pre>
				</section>
				
				<section>
					<h3>Data Type Conversion</h3>
					<pre><code>
						df['column'].astype('dtype')
					</code></pre>
				</section>
				
				<section>
					<h3>Outlier Removal</h3>
					<pre><code>
							df[df['column'] < upper_limit]
					</code></pre>
				</section>
				
				<section>
					<h3>Normalization and Scaling</h3>
					<pre><code>
from sklearn.preprocessing import MinMaxScaler, StandardScaler

scaler = MinMaxScaler()  # or StandardScaler()
df_scaled = scaler.fit_transform(df)
					</code></pre>
				</section>
				
				<section>
					<h3>Encoding Categorical Data</h3>
					<pre><code>
# Using get_dummies
pd.get_dummies(df, columns=['categorical_column'])

# Using category codes
df['categorical_column'] = df['categorical_column'].astype('category').cat.codes
					</code></pre>
				</section>
				
				<section>
					<h3>Feature Engineering</h3>
					<pre><code>
						df['new_feature'] = df['column1'] / df['column2']
					</code></pre>
				</section>
				
				<section>
					<h3>Handling Date and Time</h3>
					<pre><code>
						df['year'] = df['datetime_column'].dt.year
					</code></pre>
				</section>
				
				<section>
					<h3>Dimensionality Reduction</h3>
					<pre><code>
						from sklearn.decomposition import PCA
						
						pca = PCA(n_components=k)
						df_reduced = pca.fit_transform(df)
					</code></pre>
					<!-- Principal Component Analysis -->
					<!-- Ê¨°ÂÖÉÂâäÊ∏õ„ÅÆ1„Å§„ÅÆ‰∏ªÊàêÂàÜÂàÜÊûê -->
				</section>

				<!-- Validation -->
				<section id="validation">
					<h3>Validation</h3>
				</section>
				<section>
					<h3>Hold-Out Validation</h3>
					<pre><code>
						from sklearn.model_selection import train_test_split
						
						X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2)
					</code></pre>
				</section>
				
				<section>
					<h3>K-Fold Cross-Validation</h3>
					<pre><code>
						from sklearn.model_selection import cross_val_score, KFold
						
						kf = KFold(n_splits=5)
						scores = cross_val_score(model, X, y, cv=kf)
					</code></pre>
					<!-- We can train 5 models. -->
				</section>
				
				<section>
					<h3>Stratified K-Fold Cross-Validation</h3>
					<pre><code>
						from sklearn.model_selection import StratifiedKFold

						skf = StratifiedKFold(n_splits=5)
						scores = cross_val_score(model, X, y, cv=skf)
					</code></pre>
					<!-- Split 5 by keeping data distributed -->
				</section>

				<!-- Metrics Optimization -->
				<section id="metrics-optimization">
					<h3>Metrics Optimization</h3>
				</section>
				<section>
					<h3>Accuracy</h3>
					<pre><code>
						from sklearn.metrics import accuracy_score

						accuracy = accuracy_score(y_true, y_pred)
					</code></pre>
				</section>
				
				<section>
					<h3>Precision, Recall, and F1 Score</h3>
					<pre><code>
from sklearn.metrics import precision_score, recall_score, f1_score

precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
					</code></pre>

					<!-- ÂÅΩÈôΩÊÄß(False Positive)„ÇíÊ∏õ„Çâ„Åó„Åü„Åã„Å£„Åü„ÇâÈÅ©ÂêàÁéáÔºàprecision) -->
					<!-- ÂÅΩÈô∞ÊÄß(False Negative)„ÇíÊ∏õ„Çâ„Åó„Åü„Åã„Å£„Åü„ÇâÂÜçÁèæÁéáÔºàrecallÔºâ -->
					<!-- F1„ÅØ (2*precision*recall) / (precision + recall) -->
					<!-- https://note.nkmk.me/python-sklearn-confusion-matrix-score/ -->
				</section>
				
				<section>
						<h3>ROC-AUC Score</h3>
						<pre><code>
from sklearn.metrics import roc_auc_score

roc_auc = roc_auc_score(y_true, y_scores)
						</code></pre>
				</section>
				
				<section>
						<h3>MSE and RMSE</h3>
						<pre><code>
from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_true, y_pred)
rmse = mean_squared_error(y_true, y_pred, squared=False)
						</code></pre>
						<!-- Mean Squared Error (Âπ≥Âùá‰∫å‰πóË™§Â∑Æ)ÔºöÂ§ß„Åç„Å™Ë™§Â∑Æ„Çí„Çà„ÇäÂé≥„Åó„ÅèÊâ±„ÅÑ„Åæ„Åô„ÄÇ -->
						<!-- Root Mean Squared Error(‰∫å‰πóÂπ≥ÂùáÂπ≥ÊñπÊ†πË™§Â∑Æ)Ôºö ÂÖÉ„ÅÆ„Éá„Éº„Çø„Å®Âêå„ÅòÂçò‰Ωç„ÅßË™§Â∑Æ„ÇíË©ï‰æ°„Åß„Åç„Åæ„Åô„ÄÇ -->
				</section>
				
				<section>
						<h3>Mean Absolute Error (MAE)</h3>
						<pre><code>
from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_true, y_pred)
						</code></pre>
						<!-- Âπ≥ÂùáÁµ∂ÂØæË™§Â∑Æ: Â∑Æ„ÅÆÁµ∂ÂØæÂÄ§„Çí„Å®„Çã„Åì„Å®„Åß„ÄÅË™§Â∑Æ„ÅÆÂ§ß„Åç„Åï„ÇíËÄÉÊÖÆ„Åõ„Åö„ÄÅÂÖ¨Âπ≥„Å´Ë©ï‰æ°„Åô„Çã„ÄÇ -->
				</section>
				
				<section>
						<h3>Log Loss</h3>
						<pre><code>
from sklearn.metrics import log_loss

logloss = log_loss(y_true, y_pred_probs)
						</code></pre>
				</section>

				<!-- Ensembling -->
				<section id="ensembling">
					<h3>Ensembling</h3>
				</section>
				<section>
					<h3>Averaging</h3>
					<pre><code>
predictions = (model1.predict(X_test) + model2.predict(X_test) + model3.predict(X_test)) / 3
					</code></pre>
				</section>
				
				<section>
					<h3>Weighted Averaging</h3>
					<pre><code>
weights = [0.3, 0.4, 0.3]
predictions = weights[0]*model1.predict(X_test) + weights[1]*model2.predict(X_test) + weights[2]*model3.predict(X_test)
					</code></pre>
				</section>
				
				<section>
					<h3>Bagging</h3>
					<pre><code>
from sklearn.ensemble import BaggingClassifier

bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)
bagging_model.fit(X_train, y_train)
predictions = bagging_model.predict(X_test)
					</code></pre>
					<!-- Âêå„Åò„É¢„Éá„É´„Çí„ÄÅÈÅï„ÅÜ„Çµ„É≥„Éó„É´Êï∞„Åß‰∏¶Âàó„Å´Â≠¶Áøí„Åï„Åõ„Åü„ÅÇ„Å®„ÄÅ„Åù„ÅÆÁµêÊûú„ÅÆÂπ≥Âùá„ÇíÂèñ„Çã„ÄÇ -->
				</section>
				
				<section>
					<h3>Boosting</h3>
					<pre><code>
from sklearn.ensemble import GradientBoostingClassifier

boosting_model = GradientBoostingClassifier(n_estimators=100)
boosting_model.fit(X_train, y_train)
predictions = boosting_model.predict(X_test)
					</code></pre>
					<!-- Áõ¥Âàó„ÅÆ„Çà„ÅÜ„Å´Â≠¶Áøí„Åó„Åü„É¢„Éá„É´„ÇíÊõ¥„Å´Â≠¶Áøí„Åó„Å¶„ÄÅ10 steps„ÅÆ„É¢„Éá„É´„ÅÆÁµêÊûú „Å® 20 steps „ÅÆ„É¢„Éá„É´„ÅÆÁµêÊûú„ÅÆÂπ≥Âùá„ÇíÂèñ„Çã„ÄÇ -->
				</section>
				
				<section>
					<h3>Stacking</h3>
					<pre><code>
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

estimators = [
	('rf', RandomForestClassifier(n_estimators=10, random_state=42)),
	('svr', make_pipeline(StandardScaler(), LinearSVC(random_state=42)))
]
stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())
stacking_model.fit(X_train, y_train)
predictions = stacking_model.predict(X_test)
					</code></pre>
					<!-- ÈÅï„ÅÜ„É¢„Éá„É´„ÅÆ‰∫àÊ∏¨ÁµêÊûú„ÇíÂÖ•Âäõ„Å´„É¢„Éá„É´„ÇíÂ≠¶Áøí„Åô„Çã -->
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX],
			});
		</script>
	</body>
</html>
